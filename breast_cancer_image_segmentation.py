# -*- coding: utf-8 -*-
"""Copy of Copy_of_mini_IP(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zjii3TBxDCxOWWeOJYXAOzoNM2mqoUFn
"""

# Mount Google Drive (if your data is on Google Drive)
from google.colab import drive
drive.mount('/content/drive')

import zipfile

# Define the path to the zip file and the target extraction directory
zip_file_path = '/content/drive/MyDrive/mini.zip'
extract_path = '/content/drive/MyDrive/extracted_data/'

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# List files in the extracted directory
import os
for dirname, _, filenames in os.walk(extract_path):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from IPython.display import clear_output
!pip install tf_explain
clear_output()

# common
import os
import keras
import numpy as np
import pandas as pd
from glob import glob
import tensorflow as tf
import tensorflow.image as tfi

# Data
from keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical

# Data Viz
import matplotlib.pyplot as plt

# Model
from keras.models import Model
from keras.layers import Layer
from keras.layers import Conv2D
from keras.layers import Dropout
from keras.layers import UpSampling2D
from keras.layers import concatenate
from keras.layers import Add
from keras.layers import Multiply
from keras.layers import Input
from keras.layers import MaxPool2D
from keras.layers import BatchNormalization

# Callbacks
from keras.callbacks import Callback
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
from tf_explain.core.grad_cam import GradCAM

# Metrics
from keras.metrics import MeanIoU

def load_image(image, SIZE):
    return np.round(tfi.resize(img_to_array(load_img(image))/255.,(SIZE, SIZE)),4)

def load_images(image_paths, SIZE, mask=False, trim=None):
    if trim is not None:
        image_paths = image_paths[:trim]

    if mask:
        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))
    else:
        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))

    for i,image in enumerate(image_paths):
        img = load_image(image,SIZE)
        if mask:
            images[i] = img[:,:,:1]
        else:
            images[i] = img

    return images

def show_image(image, title=None, cmap=None, alpha=1):
    plt.imshow(image, cmap=cmap, alpha=alpha)
    if title is not None:
        plt.title(title)
    plt.axis('off')

def show_mask(image, mask, cmap=None, alpha=0.4):
    plt.imshow(image)
    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)
    plt.axis('off')

SIZE = 256

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Define the path to your dataset in Google Drive
root_path = '/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/'

# List classes (subdirectories) within the dataset path
classes = sorted(os.listdir(root_path))

# Print the sorted list of classes
print(classes)

single_mask_paths = sorted([sorted(glob(root_path + name + "/*mask.png")) for name in classes])
double_mask_paths = sorted([sorted(glob(root_path + name + "/*mask_1.png")) for name in classes])

image_paths = []
mask_paths = []
for class_path in single_mask_paths:
    for path in class_path:
        img_path = path.replace('_mask','')
        image_paths.append(img_path)
        mask_paths.append(path)

# Data augmentation (add data augmentation as needed)
from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

# Load and augment images and masks
def load_and_augment_images(image_paths, mask_paths, SIZE, num_augmentations=5):
    images = load_images(image_paths, SIZE)
    masks = load_images(mask_paths, SIZE, mask=True)
    augmented_images = []
    augmented_masks = []

    for i in range(len(images)):
        image = images[i]
        mask = masks[i]
        augmented_images.append(image)
        augmented_masks.append(mask)
        for _ in range(num_augmentations):
            seed = np.random.randint(1000)
            image_aug = datagen.random_transform(image, seed=seed)
            mask_aug = datagen.random_transform(mask, seed=seed)
            augmented_images.append(image_aug)
            augmented_masks.append(mask_aug)

    return np.array(augmented_images), np.array(augmented_masks)

# Load and augment images and masks
images, masks = load_and_augment_images(image_paths, mask_paths, SIZE, num_augmentations=2)

# Data visualization with augmented images
plt.figure(figsize=(13, 8))
for i in range(15):
    plt.subplot(3, 5, i+1)
    id = np.random.randint(len(images))
    show_mask(images[id], masks[id], cmap='jet')
plt.tight_layout()
plt.show()

show_image(load_image(image_paths[0], SIZE))

show_mask(load_image(image_paths[0], SIZE), load_image(mask_paths[0], SIZE)[:,:,0], alpha=0.6)

show_image(load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))

show_image(load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100)_mask_1.png', SIZE))

show_image(load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100)_mask.png', SIZE))

img = np.zeros((1,SIZE,SIZE,3))
mask1 = load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100)_mask_1.png', SIZE)
mask2 = load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100)_mask.png', SIZE)

img = img + mask1 + mask2
img = img[0,:,:,0]
show_image(img, cmap='gray')

show_image(load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))
plt.imshow(img, cmap='binary', alpha=0.4)
plt.axis('off')
plt.show()

show_image(load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))
plt.imshow(img, cmap='gray', alpha=0.4)
plt.axis('off')
plt.show()

show_image(load_image('/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))
plt.imshow(img, alpha=0.4)
plt.axis('off')
plt.show()

images = load_images(image_paths, SIZE)
masks = load_images(mask_paths, SIZE, mask=True)

plt.figure(figsize=(13,8))
for i in range(15):
    plt.subplot(3,5,i+1)
    id = np.random.randint(len(images))
    show_mask(images[id], masks[id], cmap='jet')
plt.tight_layout()
plt.show()

plt.figure(figsize=(13,8))
for i in range(15):
    plt.subplot(3,5,i+1)
    id = np.random.randint(len(images))
    show_mask(images[id], masks[id], cmap='binary')
plt.tight_layout()
plt.show()

plt.figure(figsize=(13,8))
for i in range(15):
    plt.subplot(3,5,i+1)
    id = np.random.randint(len(images))
    show_mask(images[id], masks[id], cmap='afmhot')
plt.tight_layout()
plt.show()

plt.figure(figsize=(13,8))
for i in range(15):
    plt.subplot(3,5,i+1)
    id = np.random.randint(len(images))
    show_mask(images[id], masks[id], cmap='copper')
plt.tight_layout()
plt.show()

class EncoderBlock(Layer):

    def __init__(self, filters, rate, pooling=True, **kwargs):
        super(EncoderBlock, self).__init__(**kwargs)

        self.filters = filters
        self.rate = rate
        self.pooling = pooling

        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')
        self.drop = Dropout(rate)
        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')
        self.pool = MaxPool2D()

    def call(self, X):
        x = self.c1(X)
        x = self.drop(x)
        x = self.c2(x)
        if self.pooling:
            y = self.pool(x)
            return y, x
        else:
            return x

    def get_config(self):
        base_config = super().get_config()
        return {
            **base_config,
            "filters":self.filters,
            'rate':self.rate,
            'pooling':self.pooling
        }

class DecoderBlock(Layer):

    def __init__(self, filters, rate, **kwargs):
        super(DecoderBlock, self).__init__(**kwargs)

        self.filters = filters
        self.rate = rate

        self.up = UpSampling2D()
        self.net = EncoderBlock(filters, rate, pooling=False)

    def call(self, X):
        X, skip_X = X
        x = self.up(X)
        c_ = concatenate([x, skip_X])
        x = self.net(c_)
        return x

    def get_config(self):
        base_config = super().get_config()
        return {
            **base_config,
            "filters":self.filters,
            'rate':self.rate,
        }

class AttentionGate(Layer):

    def __init__(self, filters, bn, **kwargs):
        super(AttentionGate, self).__init__(**kwargs)

        self.filters = filters
        self.bn = bn

        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')
        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')
        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')
        self.resample = UpSampling2D()
        self.BN = BatchNormalization()

    def call(self, X):
        X, skip_X = X

        x = self.normal(X)
        skip = self.down(skip_X)
        x = Add()([x, skip])
        x = self.learn(x)
        x = self.resample(x)
        f = Multiply()([x, skip_X])
        if self.bn:
            return self.BN(f)
        else:
            return f
        # return f

    def get_config(self):
        base_config = super().get_config()
        return {
            **base_config,
            "filters":self.filters,
            "bn":self.bn
        }

class ShowProgress(Callback):
    def on_epoch_end(self, epochs, logs=None):
        id = np.random.randint(200)
        exp = GradCAM()
        image = images[id]
        mask = masks[id]
        pred_mask = self.model.predict(image[np.newaxis,...])
        cam = exp.explain(
            validation_data=(image[np.newaxis,...], mask),
            class_index=1,
            layer_name='Attention4',
            model=self.model
        )

        plt.figure(figsize=(10,5))

        plt.subplot(1,3,1)
        plt.title("Original Mask")
        show_mask(image, mask, cmap='copper')

        plt.subplot(1,3,2)
        plt.title("Predicted Mask")
        show_mask(image, pred_mask, cmap='copper')

        plt.subplot(1,3,3)
        show_image(cam,title="GradCAM")

        plt.tight_layout()
        plt.show()

# Additional features
# Define a learning rate scheduler
from keras.callbacks import LearningRateScheduler

def learning_rate_scheduler(epoch):
    initial_lr = 0.001
    if epoch < 10:
        return initial_lr
    else:
        return initial_lr * tf.math.exp(0.1 * (10 - epoch))

lr_scheduler = LearningRateScheduler(learning_rate_scheduler)

# Implement early stopping with patience
early_stopping = EarlyStopping(patience=5, restore_best_weights=True)

# Class weights for imbalanced datasets (adjust as needed)
class_weights = {
    0: 1.0,  # Class 0 weight
    1: 2.0   # Class 1 weight
}

# Define a custom callback for model checkpointing
model_checkpoint = ModelCheckpoint("AttentionCustomUNet.h5", save_best_only=True)

# Inputs
input_layer = Input(shape=images.shape[-3:])

# Encoder
p1, c1 = EncoderBlock(32,0.1, name="Encoder1")(input_layer)
p2, c2 = EncoderBlock(64,0.1, name="Encoder2")(p1)
p3, c3 = EncoderBlock(128,0.2, name="Encoder3")(p2)
p4, c4 = EncoderBlock(256,0.2, name="Encoder4")(p3)

# Encoding
encoding = EncoderBlock(512,0.3, pooling=False, name="Encoding")(p4)

# Attention + Decoder

a1 = AttentionGate(256, bn=True, name="Attention1")([encoding, c4])
d1 = DecoderBlock(256,0.2, name="Decoder1")([encoding, a1])

a2 = AttentionGate(128, bn=True, name="Attention2")([d1, c3])
d2 = DecoderBlock(128,0.2, name="Decoder2")([d1, a2])

a3 = AttentionGate(64, bn=True, name="Attention3")([d2, c2])
d3 = DecoderBlock(64,0.1, name="Decoder3")([d2, a3])


a4 = AttentionGate(32, bn=True, name="Attention4")([d3, c1])
d4 = DecoderBlock(32,0.1, name="Decoder4")([d3, a4])

# Output
output_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)

# Model
model = Model(
    inputs=[input_layer],
    outputs=[output_layer]
)

# Compile
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy', MeanIoU(num_classes=2, name='IoU')]
)

model.summary()

# Callbacks
cb = [
    # EarlyStopping(patience=3, restore_best_weight=True), # With Segmentation I trust on eyes rather than on metrics
    ModelCheckpoint("AttentionCustomUNet.h5", save_best_only=True),
    ShowProgress()
]

# Compile the model with class weights and IoU metric
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy', MeanIoU(num_classes=2, name='IoU')]
)

# Train the model with additional callbacks
results = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,
    batch_size=8,
    callbacks=[early_stopping, model_checkpoint, lr_scheduler]
)

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)


# Config Training
BATCH_SIZE = 8
SPE = len(X_train) // BATCH_SIZE

# Training
results = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=30, # 15 will be enough for a good Model for better model go with 20+
    steps_per_epoch=SPE,
    batch_size=BATCH_SIZE,
    callbacks=cb
)

# # Config Training
# BATCH_SIZE = 8
# SPE = len(images)//BATCH_SIZE

# # Training
# results = model.fit(
#     images, masks,
#     validation_split=0.2,
#     epochs=20, # 15 will be enough for a good Model for better model go with 20+
#     steps_per_epoch=SPE,
#     batch_size=BATCH_SIZE,
#     callbacks=cb
# )



history_values = list(results.history.values())
loss, accuracy, iou, val_loss, val_accuracy, val_iou = history_values[:6]

# Unpack the training and validation metrics
loss = results.history['loss']
val_loss = results.history['val_loss']
accuracy = results.history['accuracy']
val_accuracy = results.history['val_accuracy']
iou = results.history['IoU']
val_iou = results.history['val_IoU']

# Now you can plot the metrics
plt.figure(figsize=(20, 8))

plt.subplot(1, 3, 1)
plt.title("Model Loss")
plt.plot(loss, label="Training")
plt.plot(val_loss, label="Validation")
plt.legend()
plt.grid()

plt.subplot(1, 3, 2)
plt.title("Model Accuracy")
plt.plot(accuracy, label="Training")
plt.plot(val_accuracy, label="Validation")
plt.legend()
plt.grid()

plt.subplot(1, 3, 3)
plt.title("Model IoU")
plt.plot(iou, label="Training")
plt.plot(val_iou, label="Validation")
plt.legend()
plt.grid()

plt.show()

import cv2
import numpy as np

def get_mask_box(mask):
    img = np.uint8(mask[0, :, :, 0] * 255)

    _, binary = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        color = (0, 255, 0)
        cv2.rectangle(img_bgr, (x, y), (x + w, y + h), color, 2)

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.5
        thickness = 1
        text_height = f'Height: {h}'
        text_width = f'Width: {w}'
        text_height_size = cv2.getTextSize(text_height, font, font_scale, thickness)[0]
        text_width_size = cv2.getTextSize(text_width, font, font_scale, thickness)[0]
        cv2.putText(img_bgr, text_height, (x, y - text_height_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)
        cv2.putText(img_bgr, text_width, (x + w - text_width_size[0], y + h + text_width_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)

    plt.imshow(img_bgr,cmap = None)
    plt.axis('off')

plt.figure(figsize=(20,25))
n=0
for i in range(1,(5*3)+1):
    plt.subplot(5,3,i)
    if n==0:
        id = np.random.randint(len(images))
        image = images[id]
        mask = masks[id]
        pred_mask = model.predict(image[np.newaxis,...])

        plt.title("Original Mask")
        show_mask(image, mask)
        n+=1
    elif n==1:
        plt.title("Predicted Mask")
        show_mask(image, pred_mask)
        n+=1
    elif n==2:
        pred_mask = (pred_mask>0.5).astype('float')
        plt.title("Processed Mask")
        show_mask(image, pred_mask)
        n=0
plt.tight_layout()
plt.show()

plt.figure(figsize=(20,25))
n=0
for i in range(1,(5*3)+1):
    plt.subplot(5,3,i)
    if n==0:
        id = np.random.randint(len(images))
        image = images[id]
        mask = masks[id]
        pred_mask = model.predict(image[np.newaxis,...])

        plt.title("Original Mask")
        show_mask(image, mask)
        n+=1
    elif n==1:
        plt.title("Predicted Mask")
        show_mask(image, pred_mask)
        n+=1
    elif n==2:
        pred_mask = (pred_mask>0.5).astype('float')
        plt.title("Processed Mask")
#         show_mask(image, pred_mask)
        get_mask_box(pred_mask)
        n=0
plt.tight_layout()
plt.show()

id = 12
image = images[id]
mask = model.predict(image[np.newaxis,...])
get_mask_box(mask)

# Load the model with custom objects
loaded_model = keras.models.load_model("breast_ultrasound_segmentation_model.h5", custom_objects={
    'EncoderBlock': EncoderBlock,
    'DecoderBlock': DecoderBlock,
    'AttentionGate': AttentionGate
})

# Load the model with custom objects
with CustomObjectScope({
    'EncoderBlock': EncoderBlock,
    'DecoderBlock': DecoderBlock,
    'AttentionGate': AttentionGate
}):
    loaded_model = load_model("breast_ultrasound_segmentation_model.h5")

# Inference with a single image
def segment_image(image_path, model):
    # Load and preprocess the image
    img = load_image(image_path, SIZE)

    # Make predictions
    mask = model.predict(img[np.newaxis, ...])

    return mask

# Example of segmenting a single image
image_path = '/content/drive/MyDrive/extracted_data/Dataset_BUSI_with_GT/benign/benign (100).png'  # Replace with the actual path to your image
segmented_mask = segment_image(image_path, loaded_model)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# assume y_true is the true binary mask and y_pred is the predicted mask
# both have shape (num_samples, height, width, num_channels)
y_true = y_val
y_pred = model.predict(X_val)

# threshold the predicted mask to convert to binary values
y_true_bool = (y_true > 0.5).astype(bool)
y_pred_bool = (y_pred > 0.5).astype(bool)  # Threshold the predicted mask

cm = confusion_matrix(y_true_bool.flatten(), y_pred_bool.flatten())
cr = classification_report(y_true_bool.flatten(), y_pred_bool.flatten())

print("Confusion matrix:")
print(cm)
print("Classification report:")
print(cr)
